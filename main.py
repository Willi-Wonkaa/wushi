import os
import time
import warnings
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import urllib3

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
BASE_URL = "https://wushujudges.ru/site/competition/"
HEADERS = {"User-Agent": "Mozilla/5.0"}
MAX_RETRIES = 3
SLEEP_TIME = 0.5


def clean_scores(df):
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å –Ω—É–ª–µ–≤—ã–º–∏ –∏–ª–∏ –ø—É—Å—Ç—ã–º–∏ –±–∞–ª–ª–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π DataFrame."""
    df["score"] = pd.to_numeric(df["score"], errors="coerce")  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ, –∑–∞–º–µ–Ω—è—è –æ—à–∏–±–∫–∏ –Ω–∞ NaN
    df_cleaned = df[df["score"] > 1]  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –±–∞–ª–ª–∞–º–∏ –±–æ–ª—å—à–µ 1
    return df_cleaned


def extract_age_category(df):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ 'category name'"""
    categories = [
        '–¥–µ–≤—É—à–∫–∏', '–º—É–∂—á–∏–Ω—ã', '7', '18', '11', 'cadets', 'female', '—é–Ω–æ—à–∏', '12-14–ª', '–≤–µ—Ç–µ—Ä–∞–Ω—ã', '9',
        'juniors', '—é–Ω–∏–æ—Ä–∫–∏15-17', '—Å—Ç–∞—Ä—à–µ', '–º–∞–ª—å—á–∏–∫–∏', '56', '2010', '—é–Ω–æ—à–∏/–¥–µ–≤—É—à–∫–∏', '–∂–µ–Ω—â–∏–Ω—ã',
        '—é–Ω–∏–æ—Ä—ã', '-8', 'adults', '–¥—É–≤—É—à–∫–∏', '–ª–µ—Ç', '–≤–∑—Ä–æ—Å–ª—ã–µ', '2009', '9-11', '-11', '15-17',
        '7-8', '–¥–µ–≤—É—à–∫–∏-—é–Ω–æ—à–∏', '—é–Ω–∏–æ—Ä–∫–∏', '41-55', '7-8–ª–µ—Ç', '—é–Ω–∏–æ—Ä—ã15-17', '1990', '12-14',
        'male'
    ]
    categories_set = {c.lower() for c in categories}

    def process_text(text):
        if pd.isna(text):
            return text, None
        words = re.findall(r'\b[\w-]+\b', text.lower())
        age_terms = [w for w in words if w in categories_set]
        remaining = ' '.join([w for w in re.findall(r'\b[\w-]+\b', text) if w.lower() not in categories_set])
        return remaining, ' '.join(age_terms) if age_terms else None

    processed = df['category name'].apply(process_text)
    df['category name'] = processed.apply(lambda x: x[0])
    df['age'] = processed.apply(lambda x: x[1])
    return df


def fetch_page(url):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
    for attempt in range(MAX_RETRIES):
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º verify=False –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ SSL
            response = requests.get(url, headers=HEADERS, timeout=10, verify=False)
            if response.status_code == 200:
                return response.text
            print(f"‚ö† –û—à–∏–±–∫–∞ {response.status_code}: {url}")
        except requests.exceptions.RequestException as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        time.sleep(5)
    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å: {url}")
    return None


def split_category_name(category_name):
    """–†–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –∫–æ–≤–µ—Ä –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ"""
    pattern = r"(–ö–æ–≤–µ—Ä \d+)\s*[:|-]\s*(.*)"
    match = re.match(pattern, category_name)
    if match:
        return match.group(1), match.group(2).strip()
    return "Unknown mat", category_name.strip()


def parse_competition_results(start_id, end_id):
    """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ ID"""
    results = []

    for comp_id in range(start_id, end_id + 1):
        url = f"{BASE_URL}{comp_id}"
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {url}")
        html = fetch_page(url)
        if not html:
            continue

        soup = BeautifulSoup(html, "html.parser")
        competition_name = soup.find("title").text.strip().split(" | ")[-1] if soup.find("title") else f"comp_{comp_id}"

        for category_block in soup.find_all("div", class_="d-flex"):
            category_name_tag = category_block.find("h3")
            if not category_name_tag:
                continue

            raw_category = category_name_tag.text.strip().replace("\n", " ")
            mat, category_name = split_category_name(raw_category)
            time_range = category_block.find("p").text.strip() if category_block.find("p") else ""

            table = category_block.find_next("table")
            if not table:
                continue

            headers = [th.text.strip() for th in table.find_all("th")]
            rows = [[td.text.strip() for td in tr.find_all("td")] for tr in table.find_all("tr") if tr.find_all("td")]

            if "#" in headers and "–ò–º—è" in headers:
                for row in rows:
                    if len(row) < 5 or not row[1] or not row[2]:
                        continue

                    if row[0] == competition_name:
                        continue

                    results.append({
                        "competition id": comp_id,
                        "competition name": competition_name,
                        "mat": mat,
                        "category name": category_name,
                        "place": row[0] if row else "",
                        "name": row[1] if len(row) > 1 else "",
                        "region": row[2] if len(row) > 2 else "",
                        "start time": row[3] if len(row) > 3 else "",
                        "score": row[4] if len(row) > 4 else "",
                    })
        time.sleep(SLEEP_TIME)

    df = pd.DataFrame(results)
    return df


start_id = 1
end_id = 3
# df = parse_competition_results(start_id, end_id)
# if not df.empty:
#     df.to_csv("data.csv", sep='|', index=False, encoding='utf-8')
#     print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data.csv")
#     print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
#     print(df.head(10))
# else:
#     print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")

