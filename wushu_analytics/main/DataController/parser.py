import os
import time
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import ssl
from datetime import datetime
from .dataWriter import (
    # Individual write functions
    write_competition_level,
    write_discipline_category,
    write_age_category,
    write_region,
    write_participant,
    write_competition,
    write_performance_carpet,
    write_performance_category_block,
    write_performance,
    write_user_profile,
    write_coach,
    write_tracked_participants,
    write_tracked_competition,
    write_tracked_region,
    write_tracked_category_block,
    write_tracked_carpet,
    
    # Update functions
    update_region_statistics,
    update_participant_statistics,
    update_competition_statistics,
    increment_region_stats,
    increment_participant_stats,
    increment_competition_stats,
    recalculate_region_statistics,
    recalculate_participant_statistics
) 


 
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
BASE_URL = "https://wushujudges.ru"
HEADERS = {"User-Agent": "Mozilla/5.0"}
MAX_RETRIES = 3
SLEEP_TIME = 0.5
 
 
# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
ssl._create_default_https_context = ssl._create_unverified_context
 
 
def fetch_page(url):
    print('fetching page: ', url)    
    response = requests.get(url, headers=HEADERS, verify=False)
    print('Page fetched')
    return response.text


def convert_date(date_str):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—É –∏–∑ DD.MM.YYYY –≤ YYYY-MM-DD"""
    try:
        return datetime.strptime(date_str, '%d.%m.%Y').strftime('%Y-%m-%d')
    except ValueError:
        return None
 
 
def parse_competitions():
    """–ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    url = BASE_URL
    print(f'Parsing competitions from: {url}')
 
    html = fetch_page(url)
    if not html:
        print("Failed to fetch page")
        return []
 
    soup = BeautifulSoup(html, "html.parser")
    competitions = []

    # –ù–∞—Ö–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É —Å —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è–º–∏
    table = soup.find("table", class_="table")
    if not table:
        print("Table not found")
        return []
 
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ tbody
    tbody = table.find("tbody")
    if not tbody:
        print("Tbody not found")
        return []
 
    rows = tbody.find_all("tr")
 
    for row in rows:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        if "datatable__empty" in row.get("class", []):
            continue
 
        cells = row.find_all("td")
        if len(cells) < 4:
            continue
 
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        name_cell = cells[0].find("a")
        if not name_cell:
            continue
 
        name = name_cell.text.strip()
        link = name_cell.get("href", "")
        full_link = BASE_URL + link if link else ""
 
        city = cells[1].text.strip()
        start_date = convert_date(cells[2].text.strip())
        end_date = convert_date(cells[3].text.strip())
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å
        if not start_date or not end_date:
            continue
 
        competitions.append({
            "name": name,
            "city": city,
            "start_date": start_date,
            "end_date": end_date,
            "link": full_link
        })
 
    print(f"Found {len(competitions)} competitions:")
    for comp in competitions:
        print(f"- {comp['name']} ({comp['city']}) {comp['start_date']}-{comp['end_date']}")

    return competitions
 
 

def write_competitions(competitions):
    for comp in competitions:
        competition_obj, created = write_competition(
            link=comp.get('link', ''),
            name=comp['name'],
            city=comp['city'],
            start_date=comp['start_date'],
            end_date=comp['end_date']
        )
        
        action = "–°–æ–∑–¥–∞–Ω–æ" if created else "–û–±–Ω–æ–≤–ª–µ–Ω–æ"
        print(f"{action} —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ: {competition_obj.name}")
               

 


 

def parse_competition_detail(competition_url):
    """–ü–∞—Ä—Å–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏ —Å –∫–æ–≤—Ä–∞–º–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏"""
    print(f'Parsing competition detail from: {competition_url}')
    
    html = fetch_page(competition_url)
    if not html:
        print("Failed to fetch competition page")
        return None
    
    soup = BeautifulSoup(html, "html.parser")
    print(soup)
    
    # # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è
    # title_tag = soup.find("h1") or soup.find("title")
    # competition_name = title_tag.text.strip().split(" | ")[-1] if title_tag else "Unknown"
    
    # # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    # competition_data = {
    #     "name": competition_name,
    #     "carpets": []  # –°–ø–∏—Å–æ–∫ –∫–æ–≤—Ä–æ–≤ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è–º–∏
    # }
    
    # # –ò—â–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–≤—Ä–æ–≤ (h3 —Å id="carpet-X")
    # carpet_headers = soup.find_all("h3", id=lambda x: x and x.startswith("carpet-"))
    
    # for carpet_header in carpet_headers:
    #     # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∫–æ–≤—Ä–∞
    #     carpet_id = carpet_header.get("id", "")
    #     carpet_number = extract_carpet_number_from_id(carpet_id)
        
    #     if not carpet_number:
    #         continue
            
    #     # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ö–æ–≤–µ—Ä 1")
    #     carpet_text = carpet_header.text.strip()
        
    #     # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–≤—Ä–∞
    #     carpet_data = {
    #         "carpet_number": carpet_number,
    #         "carpet_text": carpet_text,
    #         "category_blocks": []
    #     }
        
    #     # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π –±–ª–æ–∫ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∫–æ–≤—Ä–∞
    #     current_element = carpet_header.find_next_sibling()
        
    #     while current_element:
    #         # –ï—Å–ª–∏ –º—ã –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–≤–µ—Ä, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
    #         if current_element.name == "h3" and current_element.get("id", "").startswith("carpet-"):
    #             break
                
    #         # –ò—â–µ–º –±–ª–æ–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (div —Å d-flex –∫–ª–∞—Å—Å–æ–º)
    #         if current_element.name == "div" and "d-flex" in current_element.get("class", []):
    #             category_block = parse_category_block(current_element, carpet_number)
    #             if category_block:
    #                 carpet_data["category_blocks"].append(category_block)
            
    #         current_element = current_element.find_next_sibling()
        
    #     competition_data["carpets"].append(carpet_data)
    
    # print(f"Found {len(competition_data['carpets'])} carpets")
    # for carpet in competition_data["carpets"]:
    #     print(f"  Carpet {carpet['carpet_number']}: {len(carpet['category_blocks'])} category blocks")
    
    # return competition_data



def extract_carpet_number_from_id(carpet_id):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –∫–æ–≤—Ä–∞ –∏–∑ id (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'carpet-1' -> 1)"""
    import re
    match = re.search(r'carpet-(\d+)', carpet_id)
    if match:
        return int(match.group(1))
    return None




def parse_category_block(category_element, carpet_number):
    """–ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category_name_tag = category_element.find("h3")
    if not category_name_tag:
        return None
        
    category_name = category_name_tag.text.strip()
    
    # –ò—â–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è
    time_element = category_element.find("p")
    time_range = time_element.text.strip() if time_element else ""
    
    # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è–º–∏
    table = category_element.find_next("table")
    if not table:
        return None
    
    # –ü–∞—Ä—Å–∏–º —Ç–∞–±–ª–∏—Ü—É
    headers = [th.text.strip() for th in table.find_all("th")]
    rows = [[td.text.strip() for td in tr.find_all("td")] for tr in table.find_all("tr") if tr.find_all("td")]
    
    participants = []
    if "#" in headers and "–ò–º—è" in headers:
        for row in rows:
            if len(row) < 5 or not row[1] or not row[2]:
                continue
                
            participants.append({
                "place": row[0],
                "name": row[1],
                "region": row[2],
                "start_time": row[3],
                "score": row[4] if len(row) > 4 else ""
            })
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    status = determine_category_status_new(time_range, participants)
    
    # –ü–∞—Ä—Å–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    parsed_category = parse_category_name(category_name)
    
    return {
        "category_name": category_name,
        "time_range": time_range,
        "status": status,
        "participants": participants,
        "parsed": parsed_category  # —Å–æ–¥–µ—Ä–∂–∏—Ç carpet, sex, min_age, max_age, discipline
    }


def determine_category_status_new(time_range, participants):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤"""
    if not participants:
        return "future"  # –ù–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ - –∫–∞—Ç–µ–≥–æ—Ä–∏—è –µ—â–µ –Ω–µ –Ω–∞—á–∞–ª–∞—Å—å
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –æ—Ü–µ–Ω–∫–∏ —É —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    participants_with_score = [p for p in participants 
                             if p.get("score") 
                             and p.get("score").strip() != "" 
                             and p.get("score").strip() != "-"]
    
    if len(participants_with_score) == len(participants):
        return "completed"  # –í—Å–µ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ü–µ–Ω–∫–∏ - –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞
    
    if participants_with_score:
        return "current"  # –ï—Å—Ç—å –Ω–∞—á–∞–≤—à–∏–µ—Å—è –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è
    
    return "future"  # –ù–µ—Ç –æ—Ü–µ–Ω–æ–∫ - –∫–∞—Ç–µ–≥–æ—Ä–∏—è –µ—â–µ –Ω–µ –Ω–∞—á–∞–ª–∞—Å—å


def extract_carpet_number(category_name):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –∫–æ–≤—Ä–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    import re
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "–ö–æ–≤–µ—Ä 1", "–ö–æ–≤–µ—Ä 2", "–ö1", "–ö2" –∏ —Ç.–¥.
    patterns = [
        r'–ö–æ–≤–µ—Ä\s*(\d+)',
        r'–ö(\d+)',
        r'Carpet\s*(\d+)',
        r'C(\d+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, category_name, re.IGNORECASE)
        if match:
            return int(match.group(1))
    
    return None


def split_category_name(raw_name):
    """–†–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –∫–æ–≤–µ—Ä –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    parts = raw_name.split("–ö–æ–≤–µ—Ä")
    if len(parts) > 1:
        mat = parts[0].strip() + "–ö–æ–≤–µ—Ä"
        category_name = parts[1].strip()
        return mat, category_name
    return "", raw_name


def parse_competition_results(start_id, end_id):
    results = []
 
    for comp_id in range(start_id, end_id + 1):
        url = f"{BASE_URL}{comp_id}"
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {url}")
        html = fetch_page(url)
        if not html:
            continue
 
        soup = BeautifulSoup(html, "html.parser")
        competition_name = soup.find("title").text.strip().split(" | ")[-1] if soup.find("title") else f"comp_{comp_id}"
 
        for category_block in soup.find_all("div", class_="d-flex"):
            category_name_tag = category_block.find("h3")
            if not category_name_tag:
                continue
 
            raw_category = category_name_tag.text.strip().replace("\n", " ")
            mat, category_name = split_category_name(raw_category)
            time_range = category_block.find("p").text.strip() if category_block.find("p") else ""
 
            table = category_block.find_next("table")
            if not table:
                continue
 
            headers = [th.text.strip() for th in table.find_all("th")]
            rows = [[td.text.strip() for td in tr.find_all("td")] for tr in table.find_all("tr") if tr.find_all("td")]
 
            if "#" in headers and "–ò–º—è" in headers:
                for row in rows:
                    if len(row) < 5 or not row[1] or not row[2]:
                        continue
 
                    if row[0] == competition_name:
                        continue
 
                    results.append({
                        "competition id": comp_id,
                        "competition name": competition_name,
                        "mat": mat,
                        "category name": category_name,
                        "place": row[0] if row else "",
                        "name": row[1] if len(row) > 1 else "",
                        "region": row[2] if len(row) > 2 else "",
                        "start time": row[3] if len(row) > 3 else "",
                        "score": row[4] if len(row) > 4 else "",
                    })
        time.sleep(SLEEP_TIME)
 
    df = pd.DataFrame(results)
    return df
 
 
 
 
def sync_all_data(request):
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ: —Å–ø–∏—Å–æ–∫ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –∏ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
    print("=== –ù–∞—á–∞–ª–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö ===")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π
    print("1. –ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π...")
    competitions = parse_competitions()
    write_competitions(competitions)
    print(f"–°–ø–∏—Å–æ–∫ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω: {len(competitions)} —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π")
    
    # 2. –°–∫–∞—á–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–º —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏
    print("2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö...")
    from ..models import Competition
    
    all_db_competitions = Competition.objects.all()
    details_count = 0
    
    for comp in all_db_competitions:
        if comp.link:
            print(f"  - –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {comp.name}")
            detail_data = parse_competition_detail(comp.link)
            if detail_data:
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –ë–î
                # –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ –∫–∞–∫ JSON –ø–æ–ª–µ
                details_count += 1
                print(f"    ‚úì –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞")
            else:
                print(f"    ‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
        else:
            print(f"  - –ü—Ä–æ–ø—É—Å–∫ (–Ω–µ—Ç —Å—Å—ã–ª–∫–∏): {comp.name}")
    
    print(f"–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–∫–∞—á–∞–Ω–∞ –¥–ª—è {details_count} —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π")
    print("=== –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ===")
    print("Competitions written")


def parse_category_name(raw_category):
    """
    –ü–∞—Ä—Å–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç:
    - –Ω–æ–º–µ—Ä –∫–æ–≤—Ä–∞
    - –≤–æ–∑—Ä–∞—Å—Ç–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–ø–æ–ª, –º–∏–Ω –≤–æ–∑—Ä–∞—Å—Ç, –º–∞–∫—Å –≤–æ–∑—Ä–∞—Å—Ç)
    - –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É
    
    –ü—Ä–∏–º–µ—Ä—ã –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
    "–ö–æ–≤–µ—Ä 1 –ú–∞–ª—å—á–∏–∫–∏ (9-11 –ª–µ—Ç) –ß–∞–Ω—Ü—é–∞–Ω—å"
    "–ö–æ–≤–µ—Ä 2 –î–µ–≤—É—à–∫–∏ (12-14 –ª–µ—Ç) –ù–∞–Ω—å—Ü—é–∞–Ω—å"
    """
    result = {
        'carpet': 1,
        'sex': None,
        'min_age': None,
        'max_age': None,
        'discipline': None
    }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∫–æ–≤—Ä–∞
    carpet_match = re.search(r'–ö–æ–≤–µ—Ä\s*(\d+)', raw_category, re.IGNORECASE)
    if carpet_match:
        result['carpet'] = int(carpet_match.group(1))
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª
    sex_patterns = [
        (r'–ú–∞–ª—å—á–∏–∫–∏', '–ú'),
        (r'–î–µ–≤–æ—á–∫–∏', '–ñ'),
        (r'–Æ–Ω–æ—à–∏', '–ú'),
        (r'–î–µ–≤—É—à–∫–∏', '–ñ'),
        (r'–ú—É–∂—á–∏–Ω—ã', '–ú'),
        (r'–ñ–µ–Ω—â–∏–Ω—ã', '–ñ'),
        (r'–Æ–Ω–∏–æ—Ä—ã', '–ú'),
        (r'–Æ–Ω–∏–æ—Ä–∫–∏', '–ñ'),
    ]
    
    for pattern, sex in sex_patterns:
        if re.search(pattern, raw_category, re.IGNORECASE):
            result['sex'] = sex
            break
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω (9-11 –ª–µ—Ç) –∏–ª–∏ (12-14)
    age_match = re.search(r'\((\d+)\s*[-‚Äì]\s*(\d+)\s*(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)?\)', raw_category)
    if age_match:
        result['min_age'] = int(age_match.group(1))
        result['max_age'] = int(age_match.group(2))
    else:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑—Ä–∞—Å—Ç (18+) –∏–ª–∏ (–¥–æ 12)
        age_single = re.search(r'\((\d+)\+?\)', raw_category)
        if age_single:
            result['min_age'] = int(age_single.group(1))
            result['max_age'] = 99
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É - –æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ –∏–ª–∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–µ –ø–æ—Å–ª–µ –≤–æ–∑—Ä–∞—Å—Ç–∞
    # –£–±–∏—Ä–∞–µ–º –∫–æ–≤–µ—Ä, –ø–æ–ª –∏ –≤–æ–∑—Ä–∞—Å—Ç –∏–∑ —Å—Ç—Ä–æ–∫–∏
    discipline_str = raw_category
    discipline_str = re.sub(r'–ö–æ–≤–µ—Ä\s*\d+', '', discipline_str, flags=re.IGNORECASE)
    discipline_str = re.sub(r'(–ú–∞–ª—å—á–∏–∫–∏|–î–µ–≤–æ—á–∫–∏|–Æ–Ω–æ—à–∏|–î–µ–≤—É—à–∫–∏|–ú—É–∂—á–∏–Ω—ã|–ñ–µ–Ω—â–∏–Ω—ã|–Æ–Ω–∏–æ—Ä—ã|–Æ–Ω–∏–æ—Ä–∫–∏)', '', discipline_str, flags=re.IGNORECASE)
    discipline_str = re.sub(r'\(\d+\s*[-‚Äì]\s*\d+\s*(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)?\)', '', discipline_str)
    discipline_str = re.sub(r'\(\d+\+?\)', '', discipline_str)
    discipline_str = discipline_str.strip()
    
    if discipline_str:
        result['discipline'] = discipline_str
    
    return result


def full_sync_all_data():
    """
    –ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö:
    1. –°–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è
    2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è —Å–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è
    3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ –ë–î
    """
    from ..models import Competition
    from .dataWriter import write_competitions, write_competition_detail, update_competition_statistics, update_region_statistics, update_participant_statistics
    
    print("=" * 60)
    print("=== –ü–û–õ–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–• ===")
    print("=" * 60)
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π
    print("\n[1/4] –ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π...")
    competitions = parse_competitions()
    write_competitions(competitions)
    print(f"‚úì –°–ø–∏—Å–æ–∫ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω: {len(competitions)} —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π")
    
    # 2. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è –∏–∑ –ë–î
    all_db_competitions = Competition.objects.all()
    total_competitions = all_db_competitions.count()
    
    print(f"\n[2/4] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–π –¥–ª—è {total_competitions} —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π...")
    
    total_performances = 0
    total_participants = 0
    processed_competitions = 0
    
    for idx, comp in enumerate(all_db_competitions, 1):
        print(f"\n--- [{idx}/{total_competitions}] {comp.name} ---")
        
        if not comp.link:
            print("  ‚ö† –ü—Ä–æ–ø—É—Å–∫ (–Ω–µ—Ç —Å—Å—ã–ª–∫–∏)")
            continue
        
        try:
            detail_data = parse_competition_detail(comp.link)
            if not detail_data or not detail_data.get('carpets'):
                print("  ‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–≤—Ä–∞—Ö")
                continue
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            result = write_competition_detail(comp, detail_data)
            if result:
                total_participants += result['participants']
                total_performances += result['performances']
                processed_competitions += 1
                
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è
            update_competition_statistics(comp)
            
            print(f"  ‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            
        except Exception as e:
            print(f"  ‚úó –û—à–∏–±–∫–∞: {e}")
            continue
        
        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è–º–∏
        time.sleep(SLEEP_TIME)
    
    # 3. –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Å–ª–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
    print(f"\n[3/4] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤...")
    try:
        update_region_statistics()
        print("‚úì –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤: {e}")
    
    print(f"\n[4/4] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤...")
    try:
        update_participant_statistics()
        print("‚úì –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {e}")
    
    print("\n" + "=" * 60)
    print("=== –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê ===")
    print(f"–°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_competitions}/{total_competitions}")
    print(f"–ù–æ–≤—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {total_participants}")
    print(f"–ù–æ–≤—ã—Ö –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–π: {total_performances}")
    print("=" * 60)
    
    return {
        'competitions_processed': processed_competitions,
        'competitions_total': total_competitions,
        'participants': total_participants,
        'performances': total_performances
    }



